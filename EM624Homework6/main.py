# Author: Christopher Kruger
# Description: This program takes in a csv file describing the number of people from different age groups on the cause of death
# The program tells the user the comorbidity with the highest number of deaths for the population of less than 35 years of age
# The program also runs a correlation analysis and gives the user helpful charts in displaying the number of people in certain age groups who have passed
# as well as the most common categories in cause of death for those with covid


"""
Part 1 of Homework
1)
An agile approach to the analysis of the covid comorbidities would be the write the code step by step, bouncing back between the code/excel sheet/background information
while writing the code to understand what you are reading/writing as you are doing it. You can have sprints too in writing the code in seperate chunks.
First sprint is to clean the csv file as needed, second sprint being to identify necessary modules for the code and implement them, third sprint is
to open the file for parsing, etc. Each sprint is a small task and able to be flexible in the scope of work needed. If more work is to be done, it is easy
to go back and fix. Once a prototype file is made, then stakeholders (or the teacher/TA in this case) can express their thoughts on the program for improvements/suggestions

A waterfall approach is different in the sense that I would have to fully flesh out all steps of the process and understand how it fits in together
I would create a detailed plan of what is needed for the input/output based on current information, make UML diagrams or flow charts, create a concise stepping stone timeline of what I need to do,
and only then would I begin to write the code. Once writing the code, I would be following my pre-determined steps/outline until the end for a prototype to show and test.
After the prototype I would recognize what is wrong or can be changed, document this further, and then work on the changes. This adds substanial time to developing the code and getting the desired output.
It also leaves me with little flexibility.

2)
Machine Learning could be helpful in the sense that added functionality such as natural language processing (like ChatGPT or any generative pre-trained transformer) or predictability could reduce the time needed in developing
another program like this and also reduce the time needed for understanding the input file. With natural language processing, just feeding the csv file into the program would allow a user to talk to the program
and get answers based on the questions given. For predictability, it can be used for getting the percent chance that someone will live once being diagnosed with COVID-19. Based off historical data, the accurate numbers of percent chance of survival
could be published with high accuracy and help show the public that by staying healthy (going to the gym to reduce heart disease, dont smoke, etc.) it shows a direct correlation to improved chances of survival
"""
import matplotlib.pyplot as plt
import pandas as pd # For correlation analysis
import seaborn as sns # For correlation analysis

# Function to return the index of age groups
def get_index(parts):
    age_categories = ["0-24", "25-34", "35-44", "45-54", "55-64", "65-74", "75-84", "85+"] # Ignores both "Not stated" and "All ages"
    if "COVID" not in parts[2] and parts[3] in age_categories: # Skips deaths of COVID
        return age_categories.index(parts[3]) # Returns the index of the age group
    return None

# Required lists and dictionaries for keeping track of information
death_counts = [0, 0, 0, 0, 0, 0, 0, 0]
comorbidity_stats = {}

# New age group for use globally
age_groups = ["0-24", "25-34", "35-44", "45-54", "55-64", "65-74", "75-84", "85+"] # Again ignores both "Not stated" and "All ages"

# Parsing the csv file
with open("covid_comorbidities_USsummary.csv") as data_file:
    next(data_file) # Skips the header
    for row in data_file:
        data_parts = row.strip().split(",")
        age_index = get_index(data_parts)
        if age_index is not None:
            death_counts[age_index] += int(data_parts[4]) # Adds COVID-19 deaths per age group
            comorbidity_stats[data_parts[1]] = comorbidity_stats.get(data_parts[1], 0) + int(data_parts[4]) # Updates the dictionary


# Print statistics of age groups
print("Total count per Age Group:")
for count, age in zip(death_counts, age_groups): # Combines the two lists of death counts and age groupings together
    print(age,":", count)

# This next part was generated by ChatGPT to assist me in calculating the highest comorbidity with the highest deaths for those under 35, but it is incorrect
# I was unable to solve the problem in time before the deadline/midterm
max_comorbidity = None
max_deaths = 0

for comorbidity, deaths in comorbidity_stats.items():
    age_index = get_index(comorbidity)
    if age_index is not None and (age_index == "0-24" or age_index == "25-34"):
        if deaths > max_deaths:
            max_comorbidity = comorbidity
            max_deaths = deaths

print("\nComorbidity with the highest number of 'COVID-19 Deaths' for those under 35 is {} with {} deaths".format(max_comorbidity, max_deaths))
# End of section for calculating the highest comorbidity with the highest deaths for those under 35

# Creating the graphics
plt.figure(figsize=(12, 8))

# Bar Chart
plt.subplot(221)
plt.bar(age_groups, death_counts, width=0.5)
plt.title("Age Groups Killed by COVID-19")
plt.xlabel("Age Groupings")
plt.ylabel("Count")

# Pie Chart
plt.subplot(222)
plt.pie(death_counts, labels=age_groups, autopct="%1.1f%%")
plt.title("Percentage of Age Groups in COVID-19 Deaths")

# Displaying the graphics
plt.suptitle("COVID-19 Deaths per Age Group")
plt.tight_layout()
plt.show()

# Correlation analysis
# Directly cited: https://sit.instructure.com/courses/68274/files/11937421?module_item_id=1923861
# reading the file to be analyzed
df=pd.read_csv('covid_comorbidities_USsummary.csv')
# creating the correlation matrix
corr = df.corr(numeric_only=True)
# creating the graph with the correlation matrix using seaborn
sns_plot = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,
cmap='PuBu', annot=True, vmin=-1, vmax=1,)
# displaying the matrix
plt.show()
# saving the file
sns_plot.figure.savefig("Correlation_Matrix.png")

